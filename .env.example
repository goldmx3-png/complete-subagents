# OpenRouter Configuration
OPENROUTER_API_KEY=  # Get from https://openrouter.ai/keys
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Models (all open-source via OpenRouter)
MAIN_MODEL=mistralai/magistral-small-2506  # Fast 7B model
ROUTER_MODEL=mistralai/magistral-small-2506  # Same model for routing

# Alternative models:
# MAIN_MODEL=meta-llama/llama-3.1-70b-instruct
# MAIN_MODEL=google/gemini-2.0-flash-exp:free  # Free tier!

# LLM Configuration
MAX_TOKENS=4096
TEMPERATURE=0.7
ROUTER_TEMPERATURE=0.3
USE_RULE_BASED=true  # Fast rule-based routing before LLM

# Vector Store
VECTOR_STORE=qdrant
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=  # Only for Qdrant Cloud
QDRANT_COLLECTION=documents

# Embeddings
EMBEDDING_MODEL=BAAI/bge-m3
EMBEDDING_DIMENSION=1024
EMBEDDING_DEVICE=cpu  # or cuda
EMBEDDING_BATCH_SIZE=32

# Upload Directory (can be shared across services)
UPLOAD_DIRECTORY=uploads  # or use absolute path like /path/to/shared/uploads

# Reranker (optional)
RERANKER_MODEL=BAAI/bge-reranker-v2-m3
RERANKER_DEVICE=cpu
USE_RERANKER=false

# Database
DATABASE_URL=postgresql://chatbot_user:changeme@localhost:5432/chatbot
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=40

# Application Settings
MAX_CONTEXT_LENGTH=32768
MAX_CHUNKS_PER_QUERY=10
CONVERSATION_HISTORY_LIMIT=10
MAX_FILE_SIZE_MB=100
CHUNK_SIZE=1024
CHUNK_OVERLAP=100

# RAG Settings
MIN_SIMILARITY_SCORE=0.3
AMBIGUITY_THRESHOLD=0.15
TOP_K_RETRIEVAL=5
TOP_K_RERANK=10

# Query Enhancement
USE_QUERY_REWRITING=true
QUERY_REWRITE_CACHE_TTL=86400  # 24 hours

# Agentic RAG Settings
USE_AGENTIC_RAG=false  # Enable self-correcting agentic RAG with quality checking
AGENTIC_MAX_RETRIES=2  # Max retries for query rewriting if documents not relevant
AGENTIC_RELEVANCE_THRESHOLD=0.6  # Minimum relevance score (0.0-1.0)

# ===== ADVANCED RAG TECHNIQUES (2025) =====

# Hierarchical Chunking
USE_HIERARCHICAL_CHUNKING=false  # Index small chunks, retrieve large chunks for context
PARENT_CHUNK_SIZE=2000  # Size of parent chunks (full context)
CHILD_CHUNK_SIZE=400  # Size of child chunks (indexed for search)

# Metadata Extraction
USE_METADATA_EXTRACTION=false  # Auto-generate titles, summaries, keywords
EXTRACT_SUMMARIES=true  # Generate summaries for chunks
EXTRACT_KEYWORDS=true  # Extract keywords for better matching
EXTRACT_QUESTIONS=false  # Generate hypothetical questions (slower but more accurate)

# Hybrid Search (Dense + Sparse)
USE_HYBRID_SEARCH=false  # Combine semantic search + keyword matching (BM25)
HYBRID_FUSION_METHOD=rrf  # rrf (Reciprocal Rank Fusion) or weighted
HYBRID_DENSE_WEIGHT=0.7  # Weight for dense/semantic search (if method=weighted)
HYBRID_SPARSE_WEIGHT=0.3  # Weight for sparse/keyword search (if method=weighted)

# Multi-Vector Retrieval
USE_MULTI_VECTOR=false  # Index summaries/questions separately, retrieve full docs

# Contextual Compression
USE_CONTEXTUAL_COMPRESSION=false  # Filter/compress docs to query-relevant content only
COMPRESSION_METHOD=embeddings  # embeddings (fast) or llm (accurate but slower)
COMPRESSION_SIMILARITY_THRESHOLD=0.76  # Min similarity for embeddings filter

# Advanced Re-ranking
USE_ADVANCED_RERANKING=false  # Re-rank results for better relevance
RERANKING_METHOD=mmr  # mmr (diversity), cross_encoder (balanced), or llm (most accurate)
MMR_LAMBDA=0.7  # Balance: 1.0=pure relevance, 0.0=pure diversity (only for mmr)

# Classifier Model (for fast operations like grading, compression)
CLASSIFIER_MODEL=mistralai/magistral-small-2506  # Fast, cheap model for non-generation tasks

# ===== RECOMMENDED CONFIGURATIONS =====
# FAST & GOOD: USE_HIERARCHICAL_CHUNKING=true, USE_HYBRID_SEARCH=true, USE_ADVANCED_RERANKING=true (mmr)
# BALANCED: Add USE_CONTEXTUAL_COMPRESSION=true with embeddings method
# MAX ACCURACY: Enable all features, use llm for compression and reranking (slower, more expensive)

# ===== ADVANCED AGENTIC RAG IMPROVEMENTS (2025) =====

# Multi-Stage Retrieval Pipeline
USE_MULTI_STAGE_PIPELINE=true  # 5-stage pipeline: enhancement -> hybrid search -> reranking -> compression -> selection
MULTISTAGE_ENABLE_QUERY_ENHANCEMENT=true  # Generate multiple query reformulations
MULTISTAGE_ENABLE_HYBRID_SEARCH=true  # Combine vector + BM25 search
MULTISTAGE_ENABLE_RERANKING=true  # Rerank for better precision
MULTISTAGE_ENABLE_COMPRESSION=false  # Optional: compress results (slower)

# Query Enhancement Settings
QUERY_ENHANCEMENT_STRATEGY=adaptive  # adaptive (auto-choose), multi_perspective, decomposition, expansion, hyde
QUERY_ENHANCEMENT_NUM_VARIATIONS=3  # Number of query variations to generate

# Meta-Cognitive RAG (Recursive Self-Improvement)
USE_META_COGNITIVE_RAG=false  # Enable recursive research with gap analysis (2-4s per query, highest quality)
METACOG_MAX_ITERATIONS=3  # Maximum recursive iterations
METACOG_IMPROVEMENT_THRESHOLD=0.1  # Minimum improvement needed to continue
METACOG_MIN_CONFIDENCE=0.7  # Minimum confidence to accept answer

# Process Supervision (Quality Monitoring)
USE_PROCESS_SUPERVISION=true  # Monitor pipeline stages with quality checkpoints
SUPERVISION_ENABLE_FALLBACKS=true  # Auto-recover from failures
SUPERVISION_TRACK_METRICS=true  # Track performance metrics

# Iterative Refinement
USE_ITERATIVE_REFINEMENT=true  # Enable gap analysis and iterative improvement
REFINEMENT_MAX_ITERATIONS=2  # Max iterations for refinement
REFINEMENT_GAP_THRESHOLD=0.3  # Threshold for identifying gaps

# Performance Optimization
ENABLE_ADAPTIVE_ROUTING=true  # Automatically choose simple vs complex pipeline
FAST_PATH_FOR_SIMPLE_QUERIES=true  # Use fast path for simple queries (200-400ms)
SIMPLE_QUERY_WORD_THRESHOLD=5  # Word count threshold for simple queries

# Metrics and Evaluation
TRACK_RAG_METRICS=true  # Track comprehensive RAG metrics
METRICS_WINDOW_SIZE=100  # Number of recent queries to track
ENABLE_QUALITY_REPORTS=true  # Generate quality reports

# ===== PERFORMANCE PROFILES =====
#
# ‚ö° FAST MODE (200-400ms):
#   USE_MULTI_STAGE_PIPELINE=false
#   FAST_PATH_FOR_SIMPLE_QUERIES=true
#   USE_META_COGNITIVE_RAG=false
#
# ‚öñÔ∏è BALANCED MODE (800-1200ms) - RECOMMENDED:
#   USE_MULTI_STAGE_PIPELINE=true
#   MULTISTAGE_ENABLE_QUERY_ENHANCEMENT=true
#   MULTISTAGE_ENABLE_HYBRID_SEARCH=true
#   MULTISTAGE_ENABLE_RERANKING=true
#   RERANKING_METHOD=mmr
#   USE_META_COGNITIVE_RAG=false
#   ENABLE_ADAPTIVE_ROUTING=true
#
# üéØ QUALITY MODE (2-4s):
#   USE_MULTI_STAGE_PIPELINE=true
#   (all multistage features enabled)
#   USE_META_COGNITIVE_RAG=true
#   METACOG_MAX_ITERATIONS=3
#   RERANKING_METHOD=cross_encoder

# API Settings
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
CORS_ORIGINS=http://localhost:3000,http://localhost:8000
LOG_LEVEL=INFO
DEBUG_MODE=false

# Security
API_KEY_REQUIRED=false
ALLOWED_UPLOAD_EXTENSIONS=pdf,docx,txt
MAX_REQUESTS_PER_MINUTE=60

# Banking API Integration (optional)
BANKING_API_JWT_TOKEN=
BANKING_API_TIMEOUT=30
BANKING_API_MAX_RETRIES=3
BANKING_API_VERIFY_SSL=true

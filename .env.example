# ===== CORE CONFIGURATION =====

# OpenRouter Configuration
OPENROUTER_API_KEY=  # Get from https://openrouter.ai/keys
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Models (all open-source via OpenRouter)
MAIN_MODEL=mistralai/magistral-small-2506  # Fast 7B model
ROUTER_MODEL=mistralai/magistral-small-2506  # Same model for routing

# Alternative models:
# MAIN_MODEL=meta-llama/llama-3.1-70b-instruct
# MAIN_MODEL=google/gemini-2.0-flash-exp:free  # Free tier!

# LLM Configuration
MAX_TOKENS=4096
TEMPERATURE=0.7
ROUTER_TEMPERATURE=0.3

# ===== VECTOR STORE & EMBEDDINGS =====

# Vector Store
VECTOR_STORE=qdrant
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=  # Only for Qdrant Cloud
QDRANT_COLLECTION=documents

# Embeddings
EMBEDDING_MODEL=BAAI/bge-m3
EMBEDDING_DIMENSION=1024
EMBEDDING_DEVICE=cpu  # or cuda
EMBEDDING_BATCH_SIZE=32

# ===== DATABASE =====

DATABASE_URL=postgresql://chatbot_user:changeme@localhost:5432/chatbot
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=40

# ===== APPLICATION SETTINGS =====

# General Settings
MAX_CONTEXT_LENGTH=32768
MAX_CHUNKS_PER_QUERY=15  # Increased from 10 to provide more context for complex queries
CONVERSATION_HISTORY_LIMIT=10
MAX_FILE_SIZE_MB=100
UPLOAD_DIRECTORY=uploads  # or use absolute path like /path/to/shared/uploads

# RAG Settings
MIN_SIMILARITY_SCORE=0.3
AMBIGUITY_THRESHOLD=0.15

# Query Enhancement
USE_QUERY_REWRITING=true  # Enable query rewriting (can be set to false if it reduces quality)
QUERY_REWRITE_CACHE_TTL=86400  # 24 hours

# ===== RETRIEVAL CONFIGURATION =====

# Hybrid Search (Vector + BM25) - RECOMMENDED for banking docs!
ENABLE_HYBRID_SEARCH=true  # Combine semantic + keyword search for 8-15% accuracy boost
HYBRID_VECTOR_WEIGHT=0.7  # Weight for vector similarity
HYBRID_BM25_WEIGHT=0.3  # Weight for keyword matching
BM25_K1=1.5  # Term frequency saturation parameter
BM25_B=0.75  # Document length normalization

# Reranking - FAST with MiniLM model!
ENABLE_RERANKING=true  # Use cross-encoder for final reranking
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2  # FASTEST model (~80MB, 2-3s load)
RERANKER_TOP_K=20  # Retrieve this many docs before reranking
RERANKER_RETURN_TOP_K=10  # Increased from 5 to reduce aggressive filtering
RERANKER_DEVICE=cpu  # cpu or cuda
RERANKER_BATCH_SIZE=16  # Batch size for better throughput
RERANKER_LOAD_TIMEOUT=300  # Timeout for model loading in seconds

# ===== DOCUMENT PROCESSING =====

# Semantic Chunking (alternative to Markdown chunking)
USE_SEMANTIC_CHUNKING=false  # Use LLM to detect logical boundaries
SEMANTIC_CHUNK_MIN_TOKENS=200  # Minimum chunk size
SEMANTIC_CHUNK_MAX_TOKENS=800  # Maximum chunk size
SEMANTIC_CHUNK_MODEL=mistralai/mistral-small-latest  # Model for structure detection
PRESERVE_TABLES=true  # Keep tables as complete chunks when possible

# Markdown-Based Chunking (with docling PDF parser) - RECOMMENDED
USE_MARKDOWN_CHUNKING=true  # Use docling to convert PDFs/DOCS to markdown, then chunk by headers
MARKDOWN_CHUNK_SIZE_TOKENS=600  # Chunk size in tokens (400-800 recommended)
MARKDOWN_CHUNK_OVERLAP_PERCENTAGE=15  # Overlap percentage (10-20% recommended)
MARKDOWN_TABLE_SIZE_THRESHOLD=500  # Token threshold: small tables stay inline, large tables become separate chunks
MARKDOWN_PRESERVE_HEADERS=true  # Preserve header hierarchy (h1, h2, h3, h4) in chunk metadata
DOCLING_EXTRACT_TABLES=true  # Extract tables from PDFs during conversion
DOCLING_EXTRACT_IMAGES=false  # Extract images from PDFs (for future enhancement)

# ===== HIERARCHICAL METADATA =====

# Hierarchical Metadata Configuration
ENABLE_HIERARCHICAL_METADATA=true  # Enable enhanced hierarchical metadata extraction (breadcrumbs, parent-child relationships)
HIERARCHY_MAX_DEPTH=6  # Maximum heading depth to track (1-6, corresponding to h1-h6)
HIERARCHY_INCLUDE_SIBLINGS=true  # Include sibling section information in metadata
HIERARCHY_INCLUDE_NAVIGATION=true  # Add previous/next section navigation hints

# Retrieval Enhancement Configuration
ENABLE_SECTION_GROUPING=true  # Group retrieval results by document section hierarchy
ENABLE_BREADCRUMB_CONTEXT=true  # Show hierarchical breadcrumb path in retrieval results
METADATA_FILTER_BY_SECTION=false  # Enable filtering search results by specific document sections

# ===== CONTEXT FORMATTING =====

# Context Formatting Limits (to prevent bloated prompts)
MAX_FORMATTED_CHUNK_SIZE_CHARS=4000  # Maximum characters per formatted chunk (prevents oversized chunks)
MAX_TOTAL_CONTEXT_SIZE_CHARS=20000  # Maximum total context size before fallback to simple formatting
BREADCRUMB_MAX_LEVELS=3  # Show only last N levels in breadcrumb path (e.g., "...Parent > Section > Subsection")
BREADCRUMB_MAX_LENGTH=80  # Maximum character length for breadcrumb display
FORMATTING_STYLE=minimal  # Formatting verbosity: minimal (clean), normal (balanced), detailed (full metadata)
ENABLE_AUTO_FALLBACK=true  # Automatically fallback to simple formatting if context exceeds limits

# ===== API CONFIGURATION =====

# API Settings
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
CORS_ORIGINS=http://localhost:3000,http://localhost:8000
LOG_LEVEL=DEBUG  # Use DEBUG for detailed retrieval diagnostics, INFO for production
DEBUG_MODE=false

# Security
API_KEY_REQUIRED=false
ALLOWED_UPLOAD_EXTENSIONS=pdf,docx,txt
MAX_REQUESTS_PER_MINUTE=60

# ===== BANKING API INTEGRATION =====

# Banking API Integration (optional)
BANKING_API_JWT_TOKEN=
BANKING_API_TIMEOUT=30
BANKING_API_MAX_RETRIES=3
BANKING_API_VERIFY_SSL=false  # Set to false for internal/dev endpoints with self-signed certificates

# ===== PERFORMANCE RECOMMENDATIONS =====
#
# âš¡ RECOMMENDED SETUP (FAST + ACCURATE):
#   - Hybrid Search: ENABLED (vector + BM25)
#   - Reranking: ENABLED (cross-encoder)
#   - Markdown Chunking: ENABLED (structure-aware)
#   - Hierarchical Metadata: ENABLED (breadcrumbs + section grouping)
#   - Query Rewriting: OPTIONAL (test if it improves or reduces quality for your use case)
#
# This configuration provides excellent accuracy with minimal latency (500-800ms per query).
#
